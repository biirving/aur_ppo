diff --git a/src/actor_critic_2.pt b/src/actor_critic_2.pt
index 81defd1..7e6088b 100644
Binary files a/src/actor_critic_2.pt and b/src/actor_critic_2.pt differ
diff --git a/src/alt.py b/src/alt.py
index 06637a5..770f63a 100644
--- a/src/alt.py
+++ b/src/alt.py
@@ -18,7 +18,7 @@ def parse_args():
     parser = argparse.ArgumentParser()
     parser.add_argument("--exp-name", type=str, default=os.path.basename(__file__).rstrip(".py"),
         help="the name of this experiment")
-    parser.add_argument("--gym-id", type=str, default="CartPole-v1",
+    parser.add_argument("--gym-id", type=str, default="LunarLander-v2",
         help="the id of the gym environment")
     parser.add_argument("--learning-rate", type=float, default=2.5e-4,
         help="the learning rate of the optimizer")
diff --git a/src/episodic lengths_num_layers_2_dropout_0.0_num_envs_4_num_mb_4.png b/src/episodic lengths_num_layers_2_dropout_0.0_num_envs_4_num_mb_4.png
index 7a30ed7..5f7787f 100644
Binary files a/src/episodic lengths_num_layers_2_dropout_0.0_num_envs_4_num_mb_4.png and b/src/episodic lengths_num_layers_2_dropout_0.0_num_envs_4_num_mb_4.png differ
diff --git a/src/episodic returns_num_layers_2_dropout_0.0_num_envs_4_num_mb_4.png b/src/episodic returns_num_layers_2_dropout_0.0_num_envs_4_num_mb_4.png
index 571acfa..f8b59a5 100644
Binary files a/src/episodic returns_num_layers_2_dropout_0.0_num_envs_4_num_mb_4.png and b/src/episodic returns_num_layers_2_dropout_0.0_num_envs_4_num_mb_4.png differ
diff --git a/src/ppo.py b/src/ppo.py
index 1958599..3104748 100644
--- a/src/ppo.py
+++ b/src/ppo.py
@@ -313,7 +313,7 @@ class ppo():
 		smoothed_returns = self.moving_average(episodic_returns, window_size)
 		plt.plot(x_indices, episodic_returns, label='Episodic Returns')
 		plt.plot(x_indices[9:], smoothed_returns, label=f'Moving Average (Window Size = {window_size})', color='red')
-		plt.title('Episodic Returns with Moving Average for Cartpole Problem')
+		plt.title('Episodic Returns with Moving Average for ' + self.gym_id)
 		plt.xlabel('Timestep')
 		plt.ylabel('Return')
 		plt.legend()
diff --git a/src/run.py b/src/run.py
index 1e28cb6..bc99ade 100644
--- a/src/run.py
+++ b/src/run.py
@@ -26,11 +26,11 @@ def plot_curves(arr_list, legend_list, x_indices, color_list, ylabel, fig_title)
 
 if __name__=='__main__':
 	parser = argparse.ArgumentParser()
-	parser.add_argument('-id', '--gym_id', type=str, help='Id of the environment that we will use', default='CartPole-v1')
+	parser.add_argument('-id', '--gym_id', type=str, help='Id of the environment that we will use', default='LunarLander-v2')
 	parser.add_argument('-s', '--seed', type=float, help='Seed for experiment', default=1.0)
 	parser.add_argument('-ns', '--num_steps', type=int, help='Number of steps that the environment should take', default=128)
 	parser.add_argument('-gae', '--gae', type=bool, help='Generalized Advantage Estimation flag', default=True)
-	parser.add_argument('-t', '--total_timesteps', type=int, help='Total number of timesteps that we will take', default=500000)
+	parser.add_argument('-t', '--total_timesteps', type=int, help='Total number of timesteps that we will take', default=1500000)
 	parser.add_argument('-al', '--anneal_lr', type=bool, help='How to anneal our learning rate', default=True)
 	parser.add_argument('-gl', '--gae_lambda', type=float, help="the lambda for the general advantage estimation", default=0.95)
 	parser.add_argument('-ue', '--num_update_epochs', type=int, help='The  number of update epochs for the policy', default=4)
diff --git a/src/wandb/latest-run b/src/wandb/latest-run
index 172d2d0..6509aef 120000
--- a/src/wandb/latest-run
+++ b/src/wandb/latest-run
@@ -1 +1 @@
-run-20231201_214234-ephpfqat
\ No newline at end of file
+run-20231202_122639-vo1orwf9
\ No newline at end of file
